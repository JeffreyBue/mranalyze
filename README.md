# ğŸŒ MrAnalyze.com

**Comprehensive Website Route Comparison Analysis Platform**

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Node.js](https://img.shields.io/badge/node-%3E%3D16.0.0-green.svg)
![Docker](https://img.shields.io/badge/docker-compose-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ¯ Overview

MrAnalyze is a sophisticated web application designed for **comprehensive website route comparison analysis**. It provides multi-dimensional analysis across visual design, content similarity, technical implementation, and SEO optimization to help businesses identify duplicate content risks and maintain unique digital footprints across multiple domains.

**ğŸ¯ Perfect for:**
- **SEO Professionals** - Identifying duplicate content risks across multiple domains
- **Digital Agencies** - Ensuring client websites maintain unique digital footprints  
- **Content Managers** - Detecting template reuse and content cannibalization
- **Web Developers** - Analyzing technical implementation patterns across sites
- **Business Owners** - Maintaining competitive differentiation in search results

**ğŸ’¡ What Makes MrAnalyze Unique:**
The platform goes **far beyond simple similarity scoring** by providing **detailed, interactive analysis dashboards** for each dimension. Users can drill down into granular page-by-page comparisons, view side-by-side visual comparisons with annotated differences, explore detailed metric breakdowns with explanations, and access actionable improvement suggestions based on analysis results. The **real-time progress tracking** via Server-Sent Events (SSE) provides transparency into the analysis process, while the **comprehensive export options** ensure results can be shared and acted upon by teams.

### ğŸ”¥ Key Features

- **ğŸ”„ Real-time Analysis Pipeline** - Live progress tracking via Server-Sent Events (SSE)
- **ğŸ“Š Multi-Dimensional Analysis** - Visual, Content, Technical, and SEO analysis engines
- **ğŸ¨ Interactive Web Interface** - **Detailed analysis dashboards** with granular page-by-page insights
- **ğŸ“ˆ Advanced Similarity Detection** - Jaccard, Cosine, Semantic, and Content Fingerprinting algorithms
- **ğŸ³ Docker-Based Architecture** - Scalable microservices with shared data volumes
- **âš¡ Command Line Interface** - Full automation via SAR (Scrape-Analyze-Report) system
- **ğŸ“± Multi-Viewport Analysis** - Desktop, tablet, and mobile responsive design comparison
- **ğŸ›¡ï¸ Anti-Detection Scraping** - Cloudflare bypass with Puppeteer Stealth technology
- **ğŸ“‹ Actionable SEO Insights** - Priority-ranked optimization tasks with effort estimates
- **ğŸ’¾ Comprehensive Export Options** - JSON, CSV, PDF reports with detailed metrics

---

## ğŸ—ï¸ Architecture

```
ğŸ“Š ANALYSIS REQUEST FLOW:
[Web Interface] â†’ [Website API] â†’ [Analyzer API] â†’ [Analysis Engine] â†’ [Shared Data Volume]

ğŸ“¡ REAL-TIME PROGRESS UPDATES:
[Analysis Engine] â†’ [Analyzer API] â†’ [Website API] â†’ [SSE Stream] â†’ [Web Interface]

ğŸ“‹ RESULTS ACCESS:
[Web Interface] â† [Shared Data Volume] (Direct access to completed reports)
```

**ğŸ”„ How It Works:**
1. **User submits analysis** â†’ Request flows through APIs to Analysis Engine
2. **Analysis runs** â†’ Progress updates stream back in real-time via SSE
3. **Results saved** â†’ Web Interface accesses completed reports directly from shared storage
4. **User views results** â†’ Interactive dashboards powered by stored analysis data

**Frontend (Web Interface)**
- Reports List
- Report
  - Visual
  - Technical
  - Content
  - SEO
- Interactive route input validation
- Real-time progress tracking via SSE
- Results visualization and export

**Website API (`analysis.js`)**
- Express.js middleware for analysis requests
- SSE streaming for real-time updates
- Request validation and routing

**Analyzer API (`api-server.js`)**
- Backend service managing analysis execution
- Progress broadcasting and status management
- Analysis pipeline orchestration

**Analysis Engine (SAR System)**
- Node.js-based scraping and analysis scripts
- Multi-viewport website capture
- Advanced similarity detection algorithms

**Infrastructure**
- Docker Compose orchestration
- Shared `/app/shared-data/` volume
- Container networking and communication

---

## ğŸ¨ Rich Web Interface Experience

**MrAnalyze isn't just a command-line tool** - it provides a **comprehensive web-based analysis platform** with detailed interactive dashboards that rival enterprise-grade analytics tools.

### ğŸŒŸ **Why Use the Web Interface?**

**ğŸ“Š Visual Data Exploration**
- Interactive similarity matrices with sortable columns and filtering
- Color-coded scoring with hover-over explanations and context
- Side-by-side screenshot comparisons across all viewport sizes
- Real-time progress monitoring with detailed pipeline status

**ğŸ” Granular Analysis Deep-Dives**
- **Page-by-page comparison views** with annotated differences and insights
- **Metric breakdown explanations** that help interpret similarity scores
- **Interactive charts and visualizations** showing patterns across multiple sites
- **Actionable recommendations** with priority rankings and effort estimates

**ğŸ“‹ Professional Reporting**
- **Executive summary dashboards** perfect for client presentations
- **Detailed technical reports** for development teams and SEO specialists
- **Exportable insights** in multiple formats (JSON, CSV, PDF)
- **Historical analysis tracking** to monitor changes over time

**âš¡ Real-Time Experience**
- **Live progress updates** via Server-Sent Events - watch analysis happen in real-time
- **Immediate result access** as soon as analysis completes
- **No command-line expertise required** - intuitive point-and-click interface
- **Team collaboration friendly** - shareable URLs and exportable reports

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker & Docker Compose** - For containerized deployment
- **Node.js 16+** - For local development
- **8GB RAM minimum** - 16GB recommended for large analyses
- **2GB free storage** - For scraped data and analysis cache

### Installation

```bash
# Clone the repository
git clone [repository-url]
cd mranalyze

# Environment setup
cp .env.example .env
# Edit .env with your configuration

# Start with Docker Compose in DEV
docker compose up -d
# Start with Docker Compose in PROD without .env file
NODE_ENV=production docker compose up

# Visit Browser
http://localhost:8787
```

### Run Scrape Analyze Report command line.

```bash
# Go to analyzer folder
cd mranlayze.com/analyzer/

# Install Packages
npm install

# Run Command
npm run SAR
```

---

## ğŸŒ Web Interface Usage

### **VISIT HOME PAGE**

- `/` - Home page.

- `/reports/` - Latest reports.

- Choose - report to view.

- `/run_report/` - Run report.

### **RUN REPORT**

### 1. Setup Tab
- **Route Input**: Paste or upload lists of URLs for comparison
- **Validation**: Real-time URL format checking
- **Configuration**: Analysis parameters and options

### 2. Progress Tab
- **Live Updates**: Real-time terminal output streaming
- **Pipeline Status**: Current step and completion percentage
- **Resource Monitoring**: Memory usage and performance metrics

### 3. Results Tab
- **Interactive Reports**: Sortable similarity matrices
- **View Complete Report**: Complete report with all metrics
- **Action Items**: SEO recommendations and optimization tasks

---

## ğŸ› ï¸ Command Line Interface

### SAR Pipeline (Complete Analysis)

The **S**crape-**A**nalyze-**R**eport pipeline runs the complete analysis workflow:

```bash
# Basic usage - analyze URLs from ./urls directory
npm run SAR

# Custom input directory
npm run SAR ./my-websites

# Custom output destination
npm run SAR ./urls --dest=analysis_2025

# Named parameters
npm run SAR --input=./websites --dest=/directory/comparison_jan2025
```

**Pipeline Steps:**
1. ğŸ”„ **Scrape** all .txt files in input directory
2. ğŸ¨ **Visual** analysis of all scraped sites  
3. ğŸ“ **Content** analysis of all scraped sites
4. âš™ï¸ **Technical** analysis of all scraped sites
5. ğŸ” **SEO** analysis of all scraped sites
6. ğŸ“‹ **Generate** final comparison reports

### Individual Analysis Commands

#### ğŸ”„ Scraping Commands

```bash
# Scrape all URL files in directory
npm run scrape-all

# Scrape specific URL file
npm run scrape-file ./urls/websites.txt

# Scrape with test mode
npm run test
```

**Scraping Features:**
- ğŸ›¡ï¸ Cloudflare bypass with Puppeteer Stealth
- ğŸ“± Multi-viewport capture (desktop, tablet, mobile)
- ğŸ“¸ Full-page screenshots for each viewport
- ğŸ”„ Automatic retry with exponential backoff
- â±ï¸ Configurable delays between requests

#### ğŸ¨ Visual Analysis Commands

```bash
# Standard visual analysis (recommended)
npm run visual

# Light version without screenshots (faster)
npm run visual-light
```

**Visual Analysis Metrics:**
- ğŸ¨ Color palettes and usage patterns
- ğŸ”¤ Typography (fonts, sizes, weights)
- ğŸ“ Layout structures and grid systems
- ğŸ“± Responsive design patterns
- ğŸ—‚ï¸ Design system detection (Bootstrap, Tailwind, etc.)
- ğŸ‘ï¸ Visual hierarchy and emphasis
- ğŸ“¸ Screenshot similarity across viewports

#### ğŸ“ Content Analysis Commands

```bash
# Standard content analysis (balanced performance)
npm run content

# Fast mode (larger batches, less detail)
npm run content-fast

# Deep analysis (all metrics, slower)
npm run content-deep

# Light version (memory-safe)
npm run content-light
```

**Content Analysis Parameters:**
- `--batch=N` - Pages to process simultaneously (default: 10)
- `--deep` - Enable expensive semantic metrics
- `--max-tokens=N` - Maximum tokens per document (default: 5000)
- `--sample-size=N` - Text sample size for analysis (default: 10000)

**Content Similarity Metrics:**
- ğŸ“Š **Jaccard Similarity** - Token overlap percentage
- ğŸ“ˆ **Cosine Similarity** - Document vector similarity
- ğŸ” **Content Fingerprinting** - Rolling hash comparison
- ğŸ§  **Semantic Similarity** - Meaning-based comparison
- ğŸ“š **Topic Modeling** - Thematic analysis
- ğŸ“– **Readability Metrics** - Text complexity scoring

#### âš™ï¸ Technical Analysis Commands

```bash
# Run technical analysis
npm run technical

# Custom batch processing
npm run technical -- --batch=5
```

**Technical Analysis Coverage:**
- ğŸ—ƒï¸ HTML structure similarity
- ğŸ·ï¸ Meta tag comparison
- ğŸ“‹ Schema markup detection
- ğŸ› ï¸ Framework detection (React, Vue, jQuery, etc.)
- ğŸ“¦ Resource analysis (CSS, JS files)
- âš¡ Performance patterns
- ğŸ” SEO technical elements

#### ğŸ” SEO Analysis Commands

```bash
# Run SEO analysis
npm run seo
```

**SEO Analysis Features:**
- ğŸš¨ Duplicate content risk assessment
- ğŸ“ˆ Content uniqueness scoring
- ğŸ¯ Search intent analysis
- ğŸ”— Internal linking patterns
- ğŸ“± Mobile optimization checks

#### ğŸ“‹ Report Generation Commands

```bash
# Generate final reports
npm run final

# Legacy report format
npm run final-legacy
```

### Combined Analysis Commands

```bash
# Run all analysis types
npm run analyze-all

# Content analysis + report
npm run analyze-content

# Visual analysis + report
npm run analyze-visual

# Technical analysis + report
npm run analyze-technical

# SEO analysis + report
npm run analyze-seo
```

### Memory Optimization Commands

```bash
# Test memory allocation
npm run memory-test

# Clean all generated files
npm run clean-all

# Clean reports only
npm run clean

# Clean analysis cache
npm run clean-cache

# Clean final reports
npm run clean-reports
```

---

## ğŸ“¡ API Documentation

### Analysis Endpoints

#### Start Analysis
```http
POST /analyze
Content-Type: application/json

{
  "routeLists":[
    {
      "name":"instantcheckmate.com",
      "routes":[
        "https://www.instantcheckmate.com/people/john-smith/",
        "https://www.instantcheckmate.com/people/john-smith/",
        "https://www.instantcheckmate.com/people/john-smith/"
      ],
      "domain":""
    },
    {
      "name":"instantcheckmate.com",
      "routes":[
        "https://www.instantcheckmate.com/people/john-smith/",
        "https://www.instantcheckmate.com/people/john-smith/",
        "https://www.instantcheckmate.com/people/john-smith/"
      ],
      "domain":""
    }
  ]
}
```

#### Check Status
```http
GET /status/
```

#### Progress Stream (SSE)
```http
GET /progress/
```

#### Cancel Analysis
```http
POST /cancel/
```

#### Archive Report
```http
DELETE /report/:reportId

#### Get Report Summary
```http
GET /report/:reportId/summary
```

#### Check If Server Is Running
```http
GET /health
```

#### Create Lock
```http
GET /create-lock
```

#### Remove Lock
```http
GET /remove-lock
```
### Response Formats

**Analysis Status Response:**
```json
{
    "success": true,
    "message": "Analysis started",
    "timestamp": "2025-08-14T17:35:59.302Z",
    "reportId": "analyze_20250814173559"
}
```

---

## ğŸ“Š Understanding Analysis Results

### Content Analysis Metrics

#### Jaccard Similarity (0-1 Score)
- **Measures:** Word overlap between documents
- **High Score (>0.8):** Very similar vocabulary and topics
- **Use Case:** Detecting copied or templated content
- **Example:** Score of 0.75 = 75% of unique words are shared

#### Cosine Similarity (0-1 Score)
- **Measures:** Document similarity using word frequency vectors
- **High Score (>0.85):** Similar content structure and emphasis
- **Use Case:** Finding semantically similar pages
- **Advantage:** Accounts for word frequency, not just presence

#### Content Fingerprinting (0-1 Score)
- **Measures:** Exact content matches using rolling hashes
- **High Score (>0.7):** Significant verbatim content copying
- **Use Case:** Detecting plagiarism or content reuse
- **Advantage:** Very fast, memory efficient

#### Semantic Similarity (0-1 Score)
- **Measures:** Meaning-based content comparison
- **High Score (>0.8):** Similar topics and concepts
- **Use Case:** Detecting conceptual content overlap
- **Technology:** Advanced NLP and topic modeling

### Visual Analysis Metrics

#### Color Similarity
- **Primary Color Match:** Dominant color analysis
- **Palette Similarity:** Color scheme comparison
- **Brand Consistency:** Color usage patterns

#### Typography Analysis
- **Font Detection:** Typeface identification
- **Size Patterns:** Typography hierarchy analysis
- **Weight Distribution:** Text emphasis patterns

#### Layout Similarity
- **Grid Systems:** Layout structure comparison
- **Component Placement:** UI element positioning
- **Responsive Patterns:** Multi-viewport analysis

### SEO Risk Assessment

#### Duplicate Content Risk Levels
- **ğŸŸ¢ Low (0-30%):** Minimal overlap, unique content
- **ğŸŸ¡ Medium (31-60%):** Some similarities, monitor closely
- **ğŸŸ  High (61-80%):** Significant overlap, action recommended
- **ğŸ”´ Critical (81-100%):** Extensive duplication, immediate action required

---

## ğŸ“ Output Structure & Results

### **ğŸ—‚ï¸ Comprehensive Analysis Results**

Each analysis generates an **extensive collection of detailed reports and data** stored in a structured format for easy access and review:

### Report Directory Structure
```
/app/shared-data/completed_reports/analyze_YYYYMMDDHHMMSS/
â”œâ”€â”€ ğŸ“¸ scraped_sites/                           # Raw captured website data
â”‚   â”œâ”€â”€ site1.com/
â”‚   â”‚   â”œâ”€â”€ 001_route/                          # Individual page captures
â”‚   â”‚   â”‚   â”œâ”€â”€ content.json                    # Extracted text and metadata
â”‚   â”‚   â”‚   â”œâ”€â”€ content.txt                     # Clean text for analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ screenshot_desktop.png          # Desktop viewport capture
â”‚   â”‚   â”‚   â”œâ”€â”€ screenshot_mobile.png           # Mobile viewport capture
â”‚   â”‚   â”‚   â”œâ”€â”€ screenshot_tablet.png           # Tablet viewport capture
â”‚   â”‚   â”‚   â”œâ”€â”€ technical.json                  # Technical metadata and frameworks
â”‚   â”‚   â”‚   â”œâ”€â”€ visual_desktop.json             # Desktop visual analysis data
â”‚   â”‚   â”‚   â”œâ”€â”€ visual_mobile.json              # Mobile visual analysis data
â”‚   â”‚   â”‚   â”œâ”€â”€ visual_tablet.json              # Tablet visual analysis data
â”‚   â”‚   â”‚   â””â”€â”€ visual.json                     # Combined visual analysis
â”‚   â”‚   â”œâ”€â”€ 002_route/                          # Additional pages...
â”‚   â”‚   â””â”€â”€ scraping_summary.json               # Site-level scraping report
â”‚   â””â”€â”€ site2.com/                              # Additional sites...
â”œâ”€â”€ ğŸ“Š reports/                                 # Analysis results and comparisons
â”‚   â”œâ”€â”€ analysis_cache/                         # Detailed comparison matrices
â”‚   â”‚   â”œâ”€â”€ content/                            # Content similarity comparisons
â”‚   â”‚   â”‚   â””â”€â”€ [page1_vs_page2]_content.json   # Page-to-page content analysis
â”‚   â”‚   â”œâ”€â”€ technical/                          # Technical implementation comparisons
â”‚   â”‚   â”‚   â””â”€â”€ [page1_vs_page2]_technical.json # Technical similarity data
â”‚   â”‚   â”œâ”€â”€ visual/                             # Visual design comparisons
â”‚   â”‚   â”‚   â””â”€â”€ [page1_vs_page2]_visual.json    # Visual similarity metrics
â”‚   â”‚   â”œâ”€â”€ content_master_summary.json         # Overall content analysis
â”‚   â”‚   â”œâ”€â”€ technical_master_summary.json       # Overall technical analysis
â”‚   â”‚   â”œâ”€â”€ visual_master_summary.json          # Overall visual analysis
â”‚   â”‚   â””â”€â”€ [site1_vs_site2]_*_summary.json     # Site-to-site summaries
â”‚   â”œâ”€â”€ ğŸ” seo_analysis/                        # SEO risk assessment and recommendations
â”‚   â”‚   â”œâ”€â”€ comparison_reports/                 # SEO comparison between sites
â”‚   â”‚   â”‚   â””â”€â”€ [site1_vs_site2]_seo_comparison.json
â”‚   â”‚   â”œâ”€â”€ page_reports/                       # Individual page SEO analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ [site1_page1]_seo.json          # Page-specific SEO data
â”‚   â”‚   â”‚   â””â”€â”€ [site2_page1]_seo.json          # Page-specific SEO data
â”‚   â”‚   â”œâ”€â”€ SEO_ACTION_PLAN.txt                 # Strategic SEO recommendations
â”‚   â”‚   â”œâ”€â”€ SEO_ACTION_ITEMS.csv                # Trackable SEO tasks with priorities
â”‚   â”‚   â””â”€â”€ seo_master_summary.json             # Overall SEO risk assessment
â”‚   â””â”€â”€ ğŸ“‹ final_reports/                       # Executive summaries and actionable insights
â”‚       â”œâ”€â”€ actionable_items_summary.json       # Priority action items
â”‚       â”œâ”€â”€ ACTIONABLE_ITEMS_SUMMARY.txt        # Human-readable action plan
â”‚       â”œâ”€â”€ [site1_vs_site2_final_report].json  # Complete comparison report
â”‚       â”œâ”€â”€ master_final_summary.json           # Overall analysis summary
â”‚       â””â”€â”€ MASTER_SUMMARY.txt                  # Executive summary with key insights
â””â”€â”€ ğŸ“„ master_scraping_summary.txt              # Complete scraping operation summary
```

### **ğŸ¯ Key Output Files Explained**

#### **ğŸ“Š MASTER_SUMMARY.txt** - Executive Overview
**Perfect for stakeholders and decision-makers:**
- Cross-dimensional similarity scores with risk assessments
- Analysis coverage overview showing what was successfully analyzed
- Key insights and patterns identified across all dimensions
- Priority recommendations ranked by impact and effort
- Executive summary suitable for client presentations

#### **ğŸ” SEO_ACTION_PLAN.txt** - Strategic SEO Roadmap
**Comprehensive SEO optimization strategy:**
- Content differentiation strategies to reduce duplicate content risk
- Technical SEO improvements with implementation priority
- Keyword optimization recommendations based on content analysis
- Link building opportunities identified through technical analysis
- Long-term SEO strategy aligned with business goals

#### **ğŸ“‹ SEO_ACTION_ITEMS.csv** - Trackable Task List
**Project management ready action items:**
- Priority levels (High/Medium/Low) based on impact analysis
- Effort estimates (Hours/Days/Weeks) for resource planning
- Impact assessments showing expected SEO improvement
- Implementation deadlines for project timeline planning
- Assignable tasks perfect for team collaboration

#### **ğŸ¯ ACTIONABLE_ITEMS_SUMMARY.txt** - Implementation Roadmap
**Prioritized action list organized by timeline:**
- **Immediate fixes** that can be implemented within hours
- **Medium-term improvements** requiring days or weeks
- **Long-term strategic changes** for ongoing optimization
- **Resource allocation recommendations** for team planning
- **ROI predictions** based on similarity risk reduction

#### **ğŸ“„ Individual Comparison Reports** - Detailed Analysis
**Deep-dive analysis for each site pair:**
- Comprehensive similarity scoring across all dimensions
- Page-by-page comparison matrices with detailed metrics
- Visual design analysis with screenshot comparisons
- Content analysis with NLP-powered insights
- Technical implementation comparison with framework detection
- SEO risk assessment with specific recommendations

### **ğŸ’ What Makes These Reports Special**

**ğŸ¯ Actionable Insights, Not Just Data**
Every report includes specific, implementable recommendations rather than just similarity scores. You'll know exactly what to fix, how to fix it, and why it matters for your SEO strategy.

**ğŸ“Š Multiple Detail Levels**
From executive summaries perfect for stakeholder presentations to granular technical details for development teams - every audience gets the information they need in the format they prefer.

**ğŸ”„ Real-Time Accessibility**
All reports are accessible through the web interface immediately upon completion, with interactive visualizations, sortable data tables, and exportable formats for sharing and collaboration.

---

## âš™ï¸ Configuration

### Environment Variables

```bash
# Application Environment
NODE_ENV=production                    # production | development

# Service URLs
ANALYZER_SERVICE_URL=http://analyzer:3001  # Analyzer API endpoint
```

### Docker Environment

**Development Environment:**
- Uses `nodemon` for hot reloading
- Verbose logging enabled
- Debug mode active
- **âš ï¸ Note:** Server reloads can crash active analysis sessions

**Production Environment:**
- Optimized for stability
- Minimal logging
- **Recommended** for web interface analysis sessions
- No automatic server restarts

### Analysis Parameters

```bash
# Content Analysis
--batch=20                    # Pages per batch
--deep                        # Enable semantic analysis
--max-tokens=5000            # Token limit per document
--sample-size=10000          # Text sample size

# Visual Analysis  
--screenshots                # Include screenshot comparison
--viewports=desktop,mobile   # Specify viewport captures

# Technical Analysis
--batch=5                    # Conservative batch size
--frameworks                 # Deep framework detection

# Memory Optimization
--max-old-space-size=16384   # Node.js heap size (MB)
```

---

## ğŸ› Troubleshooting

### Common Issues

#### SSE Connection Problems
```bash
# Check service status
docker-compose ps

# Restart services
docker-compose restart
```

#### Memory Allocation Errors
```bash
# Increase heap size
npm run content -- --max-old-space-size=16384

# Use light analysis mode
npm run content-light

# Process in smaller batches
npm run content -- --batch=5
```

#### Analysis Failures
```bash
# Check available disk space
df -h

# Verify URL accessibility
curl -I [website-url]
```

#### Lock File Issues
```bash
# Remove stale lock files
rm -f /app/shared-data/locks/analysis.lock
```

### Performance Optimization

#### Memory Management
- Use `content-light` for large datasets
- Increase `--max-old-space-size` for complex analysis
- Process in smaller batches during peak usage
- Monitor system resources during analysis

#### Speed Optimization
- Use `content-fast` for quick overviews
- Skip screenshots with `visual-light`
- Run analysis during off-peak hours
- Scale horizontally with multiple analyzer instances

---

## ğŸ”§ Development Guide

### Local Development Setup

```bash
# Clone and install
git clone [repository-url]
cd mranalyze/analyze
npm install

cd mranalyze/website
npm install

# Development mode (website)
cd mranalyze/website
npm run dev
```
---

## ğŸ¤ Contributing

### Development Workflow

1. **Fork** the repository
2. **Create** feature branch: `git checkout -b feature/amazing-analysis`
3. **Commit** changes: `git commit -m 'Add amazing analysis capability'`
4. **Push** to branch: `git push origin feature/amazing-analysis`
5. **Submit** pull request

### Code Standards

- **ESLint** configuration for code quality
- **Prettier** for code formatting
- **Docker** for consistent environments

---

---

**Built with â¤ï¸ by Jeffrey Bue for web professionals who demand comprehensive analysis and actionable insights.**

---

*MrAnalyze.com - Comprehensive Website Route Comparison Analysis Platform*
*Version 1.0.0 | MIT License | Â© 2025*